{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os \nimport sys\nimport random\nimport math\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport json\nimport pydicom\nfrom imgaug import augmenters as iaa\nfrom tqdm import tqdm\nimport pandas as pd \nimport glob \n\nimport tensorflow as tf\ngpu_devices = tf.config.experimental.list_physical_devices('GPU')\nfor device in gpu_devices:\n    tf.config.experimental.set_memory_growth(device, True)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-24T16:44:04.717146Z","iopub.execute_input":"2022-02-24T16:44:04.717422Z","iopub.status.idle":"2022-02-24T16:44:04.723142Z","shell.execute_reply.started":"2022-02-24T16:44:04.717374Z","shell.execute_reply":"2022-02-24T16:44:04.722340Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"DATA_DIR = '/kaggle/input'\n\n# Directory to save logs and trained model\nROOT_DIR = '/kaggle/working'","metadata":{"execution":{"iopub.status.busy":"2022-02-24T16:44:07.854627Z","iopub.execute_input":"2022-02-24T16:44:07.855054Z","iopub.status.idle":"2022-02-24T16:44:07.858603Z","shell.execute_reply.started":"2022-02-24T16:44:07.855020Z","shell.execute_reply":"2022-02-24T16:44:07.857769Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"arr=np.load(DATA_DIR+'/slacs-alike-lenses/SLACS_alike_lenses_xy64.npz')\ndata_images=arr['images']\ndata_masks=arr['masks']","metadata":{"execution":{"iopub.status.busy":"2022-02-24T16:26:43.488813Z","iopub.execute_input":"2022-02-24T16:26:43.489103Z","iopub.status.idle":"2022-02-24T16:26:52.744731Z","shell.execute_reply.started":"2022-02-24T16:26:43.489073Z","shell.execute_reply":"2022-02-24T16:26:52.743941Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(data_images.shape)\nprint(data_masks.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T16:26:53.765724Z","iopub.execute_input":"2022-02-24T16:26:53.765986Z","iopub.status.idle":"2022-02-24T16:26:53.771140Z","shell.execute_reply.started":"2022-02-24T16:26:53.765955Z","shell.execute_reply":"2022-02-24T16:26:53.770453Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"i=11\n\nfig,ax=plt.subplots(1,3,figsize=(20,7))\nax[0].imshow(data_images[i,:,:,0])\nax[1].imshow(data_masks[i,:,:,0])\nax[2].imshow(data_masks[i,:,:,1])\nfor i in range(3):\n    ax[i].axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-24T16:27:21.022830Z","iopub.execute_input":"2022-02-24T16:27:21.023098Z","iopub.status.idle":"2022-02-24T16:27:21.245071Z","shell.execute_reply.started":"2022-02-24T16:27:21.023065Z","shell.execute_reply":"2022-02-24T16:27:21.244427Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Do train/test/val split for indices rather then for the actual arrays\n\n#Extract test and val are 0.2 of dataset each\nx_train,x_test,y_train,y_test= train_test_split(data_images, data_masks, test_size=0.4,random_state=42)\nx_test, x_val , y_test, y_val= train_test_split(x_test, y_test, test_size=0.5,random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T16:27:31.539941Z","iopub.execute_input":"2022-02-24T16:27:31.540199Z","iopub.status.idle":"2022-02-24T16:27:31.940322Z","shell.execute_reply.started":"2022-02-24T16:27:31.540169Z","shell.execute_reply":"2022-02-24T16:27:31.939568Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Mask-RCNN setup","metadata":{}},{"cell_type":"code","source":"!git clone 'https://github.com/leekunhee/Mask_RCNN'","metadata":{"execution":{"iopub.status.busy":"2022-02-24T16:27:36.566154Z","iopub.execute_input":"2022-02-24T16:27:36.566448Z","iopub.status.idle":"2022-02-24T16:27:44.814006Z","shell.execute_reply.started":"2022-02-24T16:27:36.566413Z","shell.execute_reply":"2022-02-24T16:27:44.813145Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Import Mask RCNN\nsys.path.append(os.path.join(ROOT_DIR, 'Mask_RCNN')) \n\nDEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs_SLACS\")\n\nweights_dir=DATA_DIR+'/mask-rcnn-coco-weights/mask_rcnn_coco.h5'\nCOCO_WEIGHTS_PATH = weights_dir\n\nsys.path.append(ROOT_DIR)\n\nfrom mrcnn.config import Config\nfrom mrcnn import model as modellib,utils\n\nimport skimage","metadata":{"execution":{"iopub.status.busy":"2022-02-24T16:44:15.133070Z","iopub.execute_input":"2022-02-24T16:44:15.133424Z","iopub.status.idle":"2022-02-24T16:44:15.145188Z","shell.execute_reply.started":"2022-02-24T16:44:15.133371Z","shell.execute_reply":"2022-02-24T16:44:15.144431Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"class CustomConfig(Config):\n    \"\"\"Configuration for training pneumonia detection on the RSNA pneumonia dataset.\n    Overrides values in the base Config class.\n    \"\"\"\n    \n    # Give the configuration a recognizable name  \n    NAME = 'GravLens'\n    \n    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n    GPU_COUNT = 1\n    IMAGES_PER_GPU = 8 \n    \n    BACKBONE = 'resnet50'\n    \n    NUM_CLASSES = 3  # background + source + lens\n    \n    IMAGE_MIN_DIM = 64\n    IMAGE_MAX_DIM = 64\n    \n    IMAGE_RESIZE_MODE = \"square\"\n    IMAGE_CHANNEL_COUNT = 3\n    \n    USE_MINI_MASK = False\n    MASK_SHAPE=[64,64]\n    \n    RPN_ANCHOR_SCALES = (32, 64, 128, 256)\n    TRAIN_ROIS_PER_IMAGE = 32\n    MAX_GT_INSTANCES = 2\n    DETECTION_MAX_INSTANCES = 2 # source and lens\n    DETECTION_MIN_CONFIDENCE = 0.68 # 1sigma confidence\n    DETECTION_NMS_THRESHOLD = 0.1\n\n    STEPS_PER_EPOCH = 100\n    \nconfig = CustomConfig()\nconfig.display()","metadata":{"execution":{"iopub.status.busy":"2022-02-24T16:45:14.683471Z","iopub.execute_input":"2022-02-24T16:45:14.684146Z","iopub.status.idle":"2022-02-24T16:45:14.699618Z","shell.execute_reply.started":"2022-02-24T16:45:14.684090Z","shell.execute_reply":"2022-02-24T16:45:14.698776Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"#Config??","metadata":{"execution":{"iopub.status.busy":"2022-02-24T16:45:22.749857Z","iopub.execute_input":"2022-02-24T16:45:22.750314Z","iopub.status.idle":"2022-02-24T16:45:22.753897Z","shell.execute_reply.started":"2022-02-24T16:45:22.750277Z","shell.execute_reply":"2022-02-24T16:45:22.752992Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n############################################################\n#  Dataset\n############################################################\n\n\n# TODO: Rewrite the methods to work with images from RAM, rather than from the disk \nclass CustomDataset(utils.Dataset):\n\n    def __init__(self, image_height,image_width, num_classes, class_map=None):\n      # Introduce fields for images and masks. Handle train/test/val split using indices\n      \n        self._image_ids = []\n        self.image_info = []\n\n        self.image_height=image_height\n        self.image_width=image_width\n\n        # Grayscale images\n        self.images=np.zeros((0,image_height,image_width,3))\n        self.masks=np.zeros((0,image_height,image_width,num_classes))\n\n        # Background is always the first class\n        self.class_info = [{\"source\": \"\", \"id\": 0, \"name\": \"BG\"}]\n        self.source_class_ids = {}\n\n    def add_image(self, source, image_id, image, mask, **kwargs):\n        image_info = {\n            \"id\": image_id,\n            \"source\": source\n        }\n        image_info.update(kwargs)\n        self.image_info.append(image_info)\n        \n        # If grayscale. Convert to RGB for consistency.\n        if image.shape[-1] != 3:\n            image = skimage.color.gray2rgb(image[:,:,0])\n        self.images=np.append(self.images,[image],axis=0)\n        self.masks=np.append(self.masks,[mask],axis=0)\n      \n\n    def load_custom(self, dataset_images,dataset_masks):\n        \"\"\"Load the train/test/val datasets\n        dataset_dir: Root directory of the dataset.\n        subset: Subset to load: train or val\n        \"\"\"\n        # Add classes\n        self.add_class(\"object\", 1, \"source_light\")\n        self.add_class(\"object\", 2, \"lens_light\")\n\n        height,width=self.images.shape[-2:]\n\n        for i,image in tqdm(enumerate(dataset_images)):\n            self.add_image(\n                source=\"object\",  ## for a single class just add the name here\n                image_id=i,  # use file name as a unique image id\n                image=image,\n                mask=dataset_masks[i])\n            \n    def load_image(self, image_id):\n        return self.images[image_id]\n    \n    def load_mask(self, image_id):\n        \"\"\"Generate instance masks for an image.\n       Returns:\n        masks: A bool array of shape [height, width, instance count] with\n            one mask per instance.\n        class_ids: a 1D array of class IDs of the instance masks.\n        \"\"\"\n        # If not a beagle dataset image, delegate to parent class.\n        image_info = self.image_info[image_id]\n        if image_info[\"source\"] != \"object\":\n            return super(self.__class__, self).load_mask(image_id)\n\n        # Convert polygons to a bitmap mask of shape\n        # [height, width, instance_count]\n        info = self.image_info[image_id]\n        mask_image = self.masks[image_id]\n\n        # array (num_classes) with 1 for detection of class and 0 otherwise\n        is_detection=(mask_image>0).any(axis=(0,1))\n\n        # Ids of object start from 1 due to background\n        detected_ids=1+np.where(is_detection)[0]\n\n        mask = np.zeros([self.image_height, self.image_width, len(detected_ids)],\n                        dtype=np.uint8)\n\n        for i,id in enumerate(detected_ids):\n            mask[:,:,i]=mask_image[:,:,id-1]\n\n        # Return mask, and array of class IDs of each instance. Since we have\n        # one class ID only, we return an array of 1s\n        return mask.astype(np.bool), detected_ids\n\n    def image_reference(self, image_id):\n        \"\"\"Return the path of the image.\"\"\"\n        info = self.image_info[image_id]\n        if info[\"source\"] == \"object\":\n            raise NotImplementedError\n        else:\n            super(self.__class__, self).image_reference(image_id)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T16:57:56.215796Z","iopub.execute_input":"2022-02-24T16:57:56.216048Z","iopub.status.idle":"2022-02-24T16:57:56.237612Z","shell.execute_reply.started":"2022-02-24T16:57:56.216020Z","shell.execute_reply":"2022-02-24T16:57:56.236806Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"# Training dataset.\ndataset_train = CustomDataset(x_train.shape[1],x_train.shape[2],y_train.shape[-1])\ndataset_train.load_custom(x_train, y_train)\ndataset_train.prepare()","metadata":{"execution":{"iopub.status.busy":"2022-02-24T16:58:00.169436Z","iopub.execute_input":"2022-02-24T16:58:00.170098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Validation dataset\ndataset_val = CustomDataset(x_train.shape[1],x_train.shape[2],y_train.shape[-1])\ndataset_val.load_custom(x_val, y_val)\ndataset_val.prepare()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model,config,dataset_train,dataset_val):\n    # *** This training schedule is an example. Update to your needs ***\n    # Since we're using a very small dataset, and starting from\n    # COCO trained weights, we don't need to train too long. Also,\n    # no need to train all layers, just the heads should do it.\n    print(\"Training network heads\")\n    model.train(dataset_train, dataset_val,\n                learning_rate=config.LEARNING_RATE,\n                epochs=100,\n                layers='heads')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = CustomConfig()\nconfig.display()\n\nprint(\"Initialize model\")\nmodel = modellib.MaskRCNN(mode=\"training\", config=config,model_dir=DEFAULT_LOGS_DIR)\n\n# Load weights\nweights_path = COCO_WEIGHTS_PATH\nprint(\"Loading weights \", weights_path)\n# Exclude the last layers because they require a matching\n# number of classes\nmodel.load_weights(weights_path, by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\"mrcnn_bbox\", \"mrcnn_mask\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Train model')\ntrain(model,config,dataset_train,dataset_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}